# ğŸš€ ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ

CNNê³¼ Deep Forestë¥¼ í•™ìŠµì‹œí‚¤ê³  ACOì™€ ê²°í•©í•˜ì—¬ ë¯¸ë¡œ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.

## ğŸ“‹ ì‚¬ì „ ì¤€ë¹„

### 1. í™˜ê²½ ì„¤ì •
```bash
# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install torch torchvision numpy scikit-learn pillow matplotlib pandas joblib psutil

# NVIDIA GPU ëª¨ë‹ˆí„°ë§ (ì„ íƒì‚¬í•­)
pip install pynvml
```

### 2. ë””ë ‰í„°ë¦¬ êµ¬ì¡° í™•ì¸
```
maze-benchmark/
â”œâ”€â”€ algorithms/           # CNN, Deep Forest, í•˜ì´ë¸Œë¦¬ë“œ ACO
â”œâ”€â”€ configs/             # ì„¤ì • íŒŒì¼
â”œâ”€â”€ datasets/            # ë¯¸ë¡œ ë°ì´í„° (train/valid/test)
â”œâ”€â”€ scripts/             # í•™ìŠµ ë° ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ utils/               # ìœ í‹¸ë¦¬í‹° (maze_io.py, profiler.py)
â””â”€â”€ output/              # ê²°ê³¼ ì €ì¥ (ìë™ ìƒì„±)
```

## ğŸƒâ€â™‚ï¸ 1ë‹¨ê³„: ë¹ ë¥¸ í…ŒìŠ¤íŠ¸

ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•ìœ¼ë¡œ ëª¨ë“  ê²ƒì´ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸:

```bash
# ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (ì ì€ ë°ì´í„°, ê°„ë‹¨í•œ ì„¤ì •)
python scripts/run_benchmark.py --quick-test

# GPU ìƒíƒœë§Œ í™•ì¸
python scripts/run_benchmark.py --gpu-check
```

## ğŸ¤– 2ë‹¨ê³„: ML ëª¨ë¸ í•™ìŠµ

### CNNê³¼ Deep Forest í•™ìŠµ
```bash
# ì „ì²´ ML ëª¨ë¸ í•™ìŠµ
python scripts/train_ml_models.py

# íŠ¹ì • ëª¨ë¸ë§Œ í•™ìŠµ
python scripts/train_ml_models.py --models cnn
python scripts/train_ml_models.py --models deep_forest

# ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
python scripts/train_ml_models.py --dry-run
```

### ì„¤ì • íŒŒì¼ ì‚¬ìš©
`configs/ml_training.json` íŒŒì¼ì„ ìˆ˜ì •í•˜ì—¬ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •:

```json
{
  "cnn": {
    "epochs": 10,
    "batch_size": 8,
    "learning_rate": 0.001
  },
  "deep_forest": {
    "n_estimators": 100,
    "n_layers": 3,
    "max_depth": 15
  }
}
```

## ğŸ¯ 3ë‹¨ê³„: í•˜ì´ë¸Œë¦¬ë“œ ë²¤ì¹˜ë§ˆí¬

### ì „ì²´ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
```bash
# ì „ì²´ íŒŒì´í”„ë¼ì¸ (ML í•™ìŠµ + í•˜ì´ë¸Œë¦¬ë“œ í‰ê°€)
python scripts/run_benchmark.py

# ê¸°ì¡´ ëª¨ë¸ë¡œ í‰ê°€ë§Œ
python scripts/run_benchmark.py --eval-only

# ê°•ì œ ì¬í•™ìŠµ
python scripts/run_benchmark.py --force-retrain
```

### ë‹¨ê³„ë³„ ì‹¤í–‰
```bash
# 1. ML ëª¨ë¸ë§Œ í•™ìŠµ
python scripts/run_benchmark.py --ml-only

# 2. í‰ê°€ë§Œ ì‹¤í–‰ (ê¸°ì¡´ ëª¨ë¸ ì‚¬ìš©)
python scripts/run_benchmark.py --eval-only
```

## ğŸ“Š 4ë‹¨ê³„: ê²°ê³¼ í™•ì¸

### ê²°ê³¼ íŒŒì¼ ìœ„ì¹˜
```
output/
â”œâ”€â”€ models/                    # í•™ìŠµëœ ëª¨ë¸
â”‚   â”œâ”€â”€ best_cnn_model.pth
â”‚   â””â”€â”€ deep_forest_model.joblib
â”œâ”€â”€ results/                   # í‰ê°€ ê²°ê³¼
â”‚   â”œâ”€â”€ benchmark_report.md    # ğŸ“‹ ìµœì¢… ë¦¬í¬íŠ¸
â”‚   â”œâ”€â”€ hybrid_evaluation.json
â”‚   â””â”€â”€ full_benchmark_results.json
â””â”€â”€ logs/                      # ë¡œê·¸ íŒŒì¼
```

### ì£¼ìš” ê²°ê³¼ íŒŒì¼
- **`benchmark_report.md`**: ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ ìµœì¢… ë¦¬í¬íŠ¸
- **`hybrid_evaluation.json`**: ìƒì„¸í•œ ì„±ëŠ¥ ë°ì´í„°
- **`training_results.json`**: ML ëª¨ë¸ í•™ìŠµ ê²°ê³¼

## âš™ï¸ ê³ ê¸‰ ì‚¬ìš©ë²•

### RTX 3060 ìµœì í™” ì„¤ì •
```bash
# ë©”ëª¨ë¦¬ ì ˆì•½ ëª¨ë“œ
python scripts/run_benchmark.py --quick-test --test-mazes 10

# íŠ¹ì • ì„¤ì •ìœ¼ë¡œ ì‹¤í–‰
python scripts/run_benchmark.py --config configs/rtx3060_optimized.json
```

### ì»¤ìŠ¤í…€ ì„¤ì • íŒŒì¼
```json
{
  "data_limits": {
    "max_train_samples": 1000,
    "max_valid_samples": 200,
    "max_test_samples": 50
  },
  "cnn": {
    "batch_size": 4,
    "epochs": 5
  },
  "evaluation": {
    "test_mazes": 20
  }
}
```

### ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
```bash
# ë³„ë„ í„°ë¯¸ë„ì—ì„œ VRAM ëª¨ë‹ˆí„°ë§
watch -n 1 nvidia-smi

# ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ê³¼ í•¨ê»˜ ì‹¤í–‰
python scripts/run_benchmark.py --verbose
```

## ğŸ› ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ì˜¤ë¥˜

1. **CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±**
   ```bash
   # ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
   python scripts/run_benchmark.py --quick-test
   ```

2. **ë°ì´í„°ì…‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ**
   ```bash
   # ë°ì´í„°ì…‹ ê²½ë¡œ í™•ì¸
   ls datasets/train/img/
   ```

3. **ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ**
   ```bash
   # ML ëª¨ë¸ ë¨¼ì € í•™ìŠµ
   python scripts/run_benchmark.py --ml-only
   ```

### ì„±ëŠ¥ íŠœë‹

RTX 3060 (6GB VRAM)ì— ìµœì í™”ëœ ì„¤ì •:

```json
{
  "cnn": {
    "batch_size": 8,
    "input_size": 200
  },
  "deep_forest": {
    "n_estimators": 50,
    "n_layers": 2
  },
  "aco_hybrid": {
    "n_ants": 30,
    "n_iterations": 50
  }
}
```

## ğŸ“ˆ ì˜ˆìƒ ê²°ê³¼

### ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ ì‹œ ì¶œë ¥ ì˜ˆì‹œ
```
ğŸ¯ ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ ìš”ì•½
================================================================================

ğŸ† ì•Œê³ ë¦¬ì¦˜ ìˆœìœ„:
  ğŸ¥‡ 1ìœ„: ACO+CNN
      ì„±ê³µë¥ : 95.2%
      í‰ê·  ê²½ë¡œ: 127.3

  ğŸ¥ˆ 2ìœ„: ACO+DeepForest
      ì„±ê³µë¥ : 93.8%
      í‰ê·  ê²½ë¡œ: 129.1

  ğŸ¥‰ 3ìœ„: ACO
      ì„±ê³µë¥ : 89.4%
      í‰ê·  ê²½ë¡œ: 135.7

âœ… ìµœê³  ì„±ê³µë¥ : 95.2% (ACO+CNN)
âš¡ ê°€ì¥ ë¹ ë¥¸ ì‹¤í–‰: 1.234ì´ˆ (ACO)

ğŸ’» ìµœì¢… VRAM ì‚¬ìš©ë¥ : 23.4%

ğŸ“Š ìƒì„¸ ê²°ê³¼ëŠ” output/results/ ë””ë ‰í„°ë¦¬ë¥¼ í™•ì¸í•˜ì„¸ìš”!
================================================================================
```

## ğŸ”— ë‹¤ìŒ ë‹¨ê³„

1. **Isaac Sim ì—°ë™**: ì‹¤ì œ ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ì—ì„œ í…ŒìŠ¤íŠ¸
2. **ë” ë§ì€ ì•Œê³ ë¦¬ì¦˜**: DQN, PPO ì¶”ê°€
3. **í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”**: Optuna ë“±ì„ ì´ìš©í•œ ìë™ íŠœë‹
4. **ì„±ëŠ¥ ë¹„êµ**: ë‹¤ë¥¸ í•˜ë“œì›¨ì–´ì—ì„œì˜ ë²¤ì¹˜ë§ˆí¬

## ğŸ’¡ íŒ

- ì²˜ìŒì—ëŠ” `--quick-test`ë¡œ ì‹œì‘í•˜ì„¸ìš”
- VRAM ì‚¬ìš©ëŸ‰ì„ ì£¼ì‹œí•˜ë©´ì„œ ë°°ì¹˜ í¬ê¸°ë¥¼ ì¡°ì •í•˜ì„¸ìš”
- í•™ìŠµëœ ëª¨ë¸ì€ ì¬ì‚¬ìš©ë˜ë¯€ë¡œ í•œ ë²ˆë§Œ í•™ìŠµí•˜ë©´ ë©ë‹ˆë‹¤
- ìƒì„¸í•œ ë¡œê·¸ê°€ í•„ìš”í•˜ë©´ `--verbose` ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”

---

**ë¬¸ì œê°€ ìˆìœ¼ë©´ ë¡œê·¸ íŒŒì¼(`training.log`, `benchmark.log`)ì„ í™•ì¸í•˜ì„¸ìš”!** ğŸ”