#!/usr/bin/env python3
"""
A* Baseline ì‹¤í—˜ ìŠ¤í¬ë¦½íŠ¸
A* ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ëª¨ë“  í…ŒìŠ¤íŠ¸ ë¯¸ë¡œì˜ ìµœì í•´ë¥¼ êµ¬í•˜ê³  baseline ì„±ëŠ¥ì„ ì¸¡ì •
"""

import sys
import time
import json
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple
import matplotlib.pyplot as plt

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

from algorithms.astar import AStarSolver, AStarResult
from utils.profiler import get_profiler, profile_execution
from utils.maze_io import get_loader, load_maze_as_array

class AStarBaseline:
    """A* ì•Œê³ ë¦¬ì¦˜ baseline ì‹¤í—˜ í´ë˜ìŠ¤"""
    
    def __init__(self, results_dir: str = "results/baseline"):
        self.results_dir = Path(results_dir)
        self.results_dir.mkdir(parents=True, exist_ok=True)
        
        # A* ì„¤ì •
        self.astar_solver = AStarSolver(diagonal_movement=False)
        self.profiler = get_profiler()
        
        # ê²°ê³¼ ì €ì¥ìš©
        self.results = {
            'optimal_solutions': {},
            'performance_metrics': {},
            'size_scaling': {},
            'memory_usage': {}
        }
    
    def run_single_maze(self, maze_data: Dict, maze_id: str) -> AStarResult:
        """ë‹¨ì¼ ë¯¸ë¡œì— ëŒ€í•œ A* ì‹¤í–‰"""
        
        maze_array = maze_data['maze']
        metadata = maze_data['metadata']
        
        # ë¯¸ë¡œ ë°ì´í„° ë³€í™˜: ìƒì„±ê¸°ì—ì„œ 0=wall, 1=pathì´ë¯€ë¡œ A*ìš©ìœ¼ë¡œ ë°˜ì „
        # A*ì—ì„œëŠ” 0=path, 1=wallì„ ê¸°ëŒ€í•¨
        converted_maze = 1 - maze_array  # 0ê³¼ 1ì„ ë’¤ë°”ê¿ˆ
        
        # ì‹œì‘ì ê³¼ ëì  ì¶”ì¶œ
        start = tuple(metadata.get('entrance', (0, 0)))
        goal = tuple(metadata.get('exit', (maze_array.shape[0]-1, maze_array.shape[1]-1)))
        
        # ì¢Œí‘œ ìˆœì„œ í™•ì¸ (x,y vs row,col)
        # ë©”íƒ€ë°ì´í„°ê°€ (x,y) í˜•ì‹ì´ë¼ë©´ (row,col)ë¡œ ë³€í™˜
        if 'entrance' in metadata:
            entrance = metadata['entrance']
            start = (entrance[1], entrance[0]) if isinstance(entrance, list) else (entrance[0], entrance[1])
        
        if 'exit' in metadata:
            exit_point = metadata['exit']
            goal = (exit_point[1], exit_point[0]) if isinstance(exit_point, list) else (exit_point[0], exit_point[1])
        
        print(f"ë¯¸ë¡œ {maze_id} ì‹¤í–‰ ì¤‘... (í¬ê¸°: {maze_array.shape}, ì‹œì‘: {start}, ë: {goal})")
        
        # ê²½ê³„ ì²´í¬
        rows, cols = converted_maze.shape
        if not (0 <= start[0] < rows and 0 <= start[1] < cols):
            print(f"âŒ ì‹œì‘ì  {start}ì´ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¨")
            result = AStarResult()
            result.solution_found = False
            result.failure_reason = f"Start point {start} out of bounds"
            return result
            
        if not (0 <= goal[0] < rows and 0 <= goal[1] < cols):
            print(f"âŒ ëì  {goal}ì´ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¨")
            result = AStarResult()
            result.solution_found = False
            result.failure_reason = f"Goal point {goal} out of bounds"
            return result
        
        # ì‹œì‘ì ê³¼ ëì ì´ í†µë¡œì¸ì§€ í™•ì¸
        if converted_maze[start[0], start[1]] != 0:
            print(f"âŒ ì‹œì‘ì  {start}ì´ ë²½ì…ë‹ˆë‹¤ (ê°’: {converted_maze[start[0], start[1]]})")
            # ì‹œì‘ì ì„ ê°•ì œë¡œ í†µë¡œë¡œ ë§Œë“¤ê¸°
            converted_maze[start[0], start[1]] = 0
            print(f"âœ… ì‹œì‘ì ì„ í†µë¡œë¡œ ë³€ê²½")
            
        if converted_maze[goal[0], goal[1]] != 0:
            print(f"âŒ ëì  {goal}ì´ ë²½ì…ë‹ˆë‹¤ (ê°’: {converted_maze[goal[0], goal[1]]})")
            # ëì ì„ ê°•ì œë¡œ í†µë¡œë¡œ ë§Œë“¤ê¸°
            converted_maze[goal[0], goal[1]] = 0
            print(f"âœ… ëì ì„ í†µë¡œë¡œ ë³€ê²½")
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘
        self.profiler.start_monitoring()
        start_time = time.time()
        
        try:
            # A* ì‹¤í–‰ (ë³€í™˜ëœ ë¯¸ë¡œ ì‚¬ìš©)
            result = self.astar_solver.solve(converted_maze, start, goal)
        except Exception as e:
            print(f"âŒ A* ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            result = AStarResult()
            result.solution_found = False
            result.failure_reason = str(e)
        
        # ì„±ëŠ¥ ì¸¡ì • ì™„ë£Œ
        execution_time = time.time() - start_time
        self.profiler.stop_monitoring()
        performance_data = self.profiler.get_summary_stats()
        
        # ê²°ê³¼ ë³´ì™„
        result.maze_id = maze_id
        result.maze_size = maze_array.shape
        result.execution_time = execution_time
        result.vram_usage = performance_data.get('vram_used_mb', {}).get('peak', 0)
        result.cpu_utilization = performance_data.get('cpu_percent', {}).get('avg', 0)
        result.gpu_utilization = performance_data.get('gpu_percent', {}).get('avg', 0)
        
        if result.solution_found:
            print(f"âœ… ì„±ê³µ! ê²½ë¡œ ê¸¸ì´: {result.solution_length}, ì‹¤í–‰ì‹œê°„: {execution_time:.3f}ì´ˆ")
        else:
            print(f"âŒ ì‹¤íŒ¨: {result.failure_reason}")
        
        return result
    
    def run_size_scaling_test(self, mazes_by_size: Dict[str, List]):
        """ë¯¸ë¡œ í¬ê¸°ë³„ ì„±ëŠ¥ ìŠ¤ì¼€ì¼ë§ í…ŒìŠ¤íŠ¸"""
        
        print("\n=== ë¯¸ë¡œ í¬ê¸°ë³„ ìŠ¤ì¼€ì¼ë§ í…ŒìŠ¤íŠ¸ ===")
        
        size_results = {}
        
        for size_category, maze_list in mazes_by_size.items():
            print(f"\ní¬ê¸° ì¹´í…Œê³ ë¦¬: {size_category}")
            
            category_results = []
            
            for maze_data, maze_id in maze_list[:5]:  # ê° í¬ê¸°ë³„ë¡œ 5ê°œì”©ë§Œ í…ŒìŠ¤íŠ¸
                result = self.run_single_maze(maze_data, maze_id)
                category_results.append({
                    'maze_id': maze_id,
                    'execution_time': result.execution_time,
                    'solution_length': result.solution_length,
                    'success': result.solution_found,
                    'total_cells': result.maze_size[0] * result.maze_size[1]
                })
            
            # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„ ê³„ì‚°
            successful_results = [r for r in category_results if r['success']]
            
            if successful_results:
                size_results[size_category] = {
                    'avg_execution_time': np.mean([r['execution_time'] for r in successful_results]),
                    'avg_solution_length': np.mean([r['solution_length'] for r in successful_results]),
                    'success_rate': len(successful_results) / len(category_results),
                    'avg_cells': np.mean([r['total_cells'] for r in category_results]),
                    'sample_count': len(category_results)
                }
        
        self.results['size_scaling'] = size_results
        return size_results
    
    def run_baseline_experiment(self, dataset_subset: str = "test", sample_limit: int = 100):
        """ì „ì²´ baseline ì‹¤í—˜ ì‹¤í–‰"""
        
        print("=== A* Baseline ì‹¤í—˜ ì‹œì‘ ===")
        
        # ë°ì´í„°ì…‹ ë¡œë” ì´ˆê¸°í™”
        print(f"ë°ì´í„°ì…‹ ë¡œë” ì´ˆê¸°í™” ì¤‘...")
        loader = get_loader()
        
        # í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ID ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        sample_ids = loader.get_sample_ids(dataset_subset)
        
        if not sample_ids:
            print("âŒ ìƒ˜í”Œ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return
        
        # ìƒ˜í”Œ ìˆ˜ ì œí•œ
        if len(sample_ids) > sample_limit:
            sample_ids = sample_ids[:sample_limit]
        
        print(f"âœ… {len(sample_ids)} ê°œ ë¯¸ë¡œ ë¡œë“œ ì™„ë£Œ")
        
        # ë¯¸ë¡œ ë°ì´í„° ë³€í™˜
        mazes = {}
        for sample_id in sample_ids:
            try:
                maze_array, metadata = load_maze_as_array(sample_id, dataset_subset)
                mazes[sample_id] = {
                    'maze': maze_array,
                    'metadata': metadata
                }
            except Exception as e:
                print(f"âŒ ë¯¸ë¡œ {sample_id} ë¡œë“œ ì‹¤íŒ¨: {e}")
                continue
        
        # í¬ê¸°ë³„ ë¶„ë¥˜
        mazes_by_size = self._categorize_by_size(mazes)
        
        # 1. ì „ì²´ ë¯¸ë¡œ ì‹¤í–‰
        print("\n=== ì „ì²´ ë¯¸ë¡œ A* ì‹¤í–‰ ===")
        all_results = []
        optimal_solutions = {}
        
        for i, (maze_id, maze_data) in enumerate(mazes.items()):
            if i >= sample_limit:
                break
                
            result = self.run_single_maze(maze_data, maze_id)
            all_results.append(result)
            
            # ìµœì í•´ ì €ì¥
            if result.solution_found:
                optimal_solutions[maze_id] = {
                    'optimal_length': result.solution_length,
                    'optimal_path': result.path,
                    'execution_time': result.execution_time
                }
            
            # ì§„í–‰ìƒí™© ì¶œë ¥
            if (i + 1) % 10 == 0:
                success_count = sum(1 for r in all_results if r.solution_found)
                print(f"ì§„í–‰: {i+1}/{min(len(mazes), sample_limit)} "
                      f"(ì„±ê³µë¥ : {success_count/(i+1)*100:.1f}%)")
        
        # 2. í¬ê¸°ë³„ ìŠ¤ì¼€ì¼ë§ í…ŒìŠ¤íŠ¸
        size_scaling = self.run_size_scaling_test(mazes_by_size)
        
        # 3. ì „ì²´ í†µê³„ ê³„ì‚°
        self._calculate_overall_statistics(all_results)
        
        # 4. ê²°ê³¼ ì €ì¥
        self._save_results(optimal_solutions)
        
        # 5. ì‹œê°í™”
        self._create_visualizations()
        
        print("\n=== A* Baseline ì‹¤í—˜ ì™„ë£Œ ===")
        self._print_summary()
    
    def _categorize_by_size(self, mazes: Dict) -> Dict[str, List]:
        """ë¯¸ë¡œë¥¼ í¬ê¸°ë³„ë¡œ ë¶„ë¥˜"""
        categories = {
            'small': [],    # 50x50 ì´í•˜
            'medium': [],   # 51x51 ~ 100x100
            'large': [],    # 101x101 ~ 150x150
            'xlarge': []    # 151x151 ì´ìƒ
        }
        
        for maze_id, maze_data in mazes.items():
            size = maze_data['maze'].shape[0]
            
            if size <= 50:
                categories['small'].append((maze_data, maze_id))
            elif size <= 100:
                categories['medium'].append((maze_data, maze_id))
            elif size <= 150:
                categories['large'].append((maze_data, maze_id))
            else:
                categories['xlarge'].append((maze_data, maze_id))
        
        return categories
    
    def _calculate_overall_statistics(self, results: List[AStarResult]):
        """ì „ì²´ í†µê³„ ê³„ì‚°"""
        
        successful_results = [r for r in results if r.solution_found]
        
        if not successful_results:
            print("âŒ ì„±ê³µí•œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        stats = {
            'total_mazes': len(results),
            'successful_mazes': len(successful_results),
            'success_rate': len(successful_results) / len(results),
            'avg_execution_time': np.mean([r.execution_time for r in successful_results]),
            'std_execution_time': np.std([r.execution_time for r in successful_results]),
            'avg_solution_length': np.mean([r.solution_length for r in successful_results]),
            'std_solution_length': np.std([r.solution_length for r in successful_results]),
            'min_execution_time': min(r.execution_time for r in successful_results),
            'max_execution_time': max(r.execution_time for r in successful_results),
            'avg_vram_usage': np.mean([r.vram_usage for r in results if r.vram_usage > 0]),
            'avg_cpu_usage': np.mean([r.cpu_utilization for r in results if r.cpu_utilization > 0])
        }
        
        self.results['performance_metrics'] = stats
    
    def _save_results(self, optimal_solutions: Dict):
        """ê²°ê³¼ ì €ì¥"""
        
        # ìµœì í•´ ì €ì¥
        optimal_path = self.results_dir / "optimal_solutions.json"
        with open(optimal_path, 'w') as f:
            # NumPy ë°°ì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            serializable_solutions = {}
            for maze_id, solution in optimal_solutions.items():
                serializable_solutions[maze_id] = {
                    'optimal_length': solution['optimal_length'],
                    'optimal_path': [list(point) for point in solution['optimal_path']],
                    'execution_time': solution['execution_time']
                }
            json.dump(serializable_solutions, f, indent=2)
        
        # ì „ì²´ ê²°ê³¼ ì €ì¥
        results_path = self.results_dir / "astar_baseline_results.json"
        with open(results_path, 'w') as f:
            json.dump(self.results, f, indent=2)
        
        print(f"âœ… ê²°ê³¼ ì €ì¥: {results_path}")
        print(f"âœ… ìµœì í•´ ì €ì¥: {optimal_path}")
    
    def _create_visualizations(self):
        """ê²°ê³¼ ì‹œê°í™”"""
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # 1. í¬ê¸°ë³„ ì‹¤í–‰ì‹œê°„
        if 'size_scaling' in self.results:
            size_data = self.results['size_scaling']
            sizes = list(size_data.keys())
            times = [size_data[s]['avg_execution_time'] for s in sizes]
            
            axes[0,0].bar(sizes, times)
            axes[0,0].set_title('ë¯¸ë¡œ í¬ê¸°ë³„ í‰ê·  ì‹¤í–‰ì‹œê°„')
            axes[0,0].set_ylabel('ì‹¤í–‰ì‹œê°„ (ì´ˆ)')
        
        # 2. í¬ê¸°ë³„ ì„±ê³µë¥ 
        if 'size_scaling' in self.results:
            success_rates = [size_data[s]['success_rate'] * 100 for s in sizes]
            
            axes[0,1].bar(sizes, success_rates)
            axes[0,1].set_title('ë¯¸ë¡œ í¬ê¸°ë³„ ì„±ê³µë¥ ')
            axes[0,1].set_ylabel('ì„±ê³µë¥  (%)')
            axes[0,1].set_ylim(0, 100)
        
        # 3. ì…€ ê°œìˆ˜ vs ì‹¤í–‰ì‹œê°„ ìƒê´€ê´€ê³„
        if 'size_scaling' in self.results:
            cell_counts = [size_data[s]['avg_cells'] for s in sizes]
            
            axes[1,0].scatter(cell_counts, times)
            axes[1,0].set_title('ë¯¸ë¡œ í¬ê¸° vs ì‹¤í–‰ì‹œê°„')
            axes[1,0].set_xlabel('ì´ ì…€ ê°œìˆ˜')
            axes[1,0].set_ylabel('ì‹¤í–‰ì‹œê°„ (ì´ˆ)')
        
        # 4. A* ì„±ëŠ¥ ìš”ì•½
        if 'performance_metrics' in self.results:
            metrics = self.results['performance_metrics']
            labels = ['ì„±ê³µë¥ ', 'í‰ê·  ì‹¤í–‰ì‹œê°„', 'í‰ê·  ê²½ë¡œê¸¸ì´']
            values = [
                metrics['success_rate'] * 100,
                metrics['avg_execution_time'],
                metrics['avg_solution_length'] / 100  # ìŠ¤ì¼€ì¼ ì¡°ì •
            ]
            
            axes[1,1].bar(labels, values)
            axes[1,1].set_title('A* ì „ì²´ ì„±ëŠ¥ ìš”ì•½')
        
        plt.tight_layout()
        
        # ì €ì¥
        viz_path = self.results_dir / "astar_baseline_analysis.png"
        plt.savefig(viz_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… ì‹œê°í™” ì €ì¥: {viz_path}")
    
    def _print_summary(self):
        """ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        
        if 'performance_metrics' not in self.results:
            return
        
        metrics = self.results['performance_metrics']
        
        print(f"""
ğŸ¯ A* Baseline ì‹¤í—˜ ê²°ê³¼ ìš”ì•½

ğŸ“Š ì „ì²´ ì„±ëŠ¥:
   â€¢ ì´ ë¯¸ë¡œ ìˆ˜: {metrics['total_mazes']}
   â€¢ ì„±ê³µ ë¯¸ë¡œ ìˆ˜: {metrics['successful_mazes']}
   â€¢ ì„±ê³µë¥ : {metrics['success_rate']*100:.1f}%

â±ï¸ ì‹¤í–‰ ì„±ëŠ¥:
   â€¢ í‰ê·  ì‹¤í–‰ì‹œê°„: {metrics['avg_execution_time']:.3f}ì´ˆ (Â±{metrics['std_execution_time']:.3f})
   â€¢ ìµœë‹¨ ì‹¤í–‰ì‹œê°„: {metrics['min_execution_time']:.3f}ì´ˆ
   â€¢ ìµœì¥ ì‹¤í–‰ì‹œê°„: {metrics['max_execution_time']:.3f}ì´ˆ

ğŸ›¤ï¸ ê²½ë¡œ í’ˆì§ˆ:
   â€¢ í‰ê·  ê²½ë¡œ ê¸¸ì´: {metrics['avg_solution_length']:.1f} (Â±{metrics['std_solution_length']:.1f})

ğŸ’» ì‹œìŠ¤í…œ ìì›:
   â€¢ í‰ê·  VRAM ì‚¬ìš©ëŸ‰: {metrics.get('avg_vram_usage', 0):.1f}MB
   â€¢ í‰ê·  CPU ì‚¬ìš©ë¥ : {metrics.get('avg_cpu_usage', 0):.1f}%

ğŸš€ ì´ì œ ê°•í™”í•™ìŠµ ëª¨ë¸ë“¤ì„ ì´ baselineê³¼ ë¹„êµí•´ë³´ì„¸ìš”!
   python scripts/train.py algo=DQN --baseline=astar
   python scripts/train.py algo=PPO --baseline=astar
        """)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    import argparse
    
    parser = argparse.ArgumentParser(description='A* Baseline ì‹¤í—˜')
    parser.add_argument('--subset', type=str, default='test', 
                       help='ë°ì´í„°ì…‹ ë¶„í•  (train/valid/test)')
    parser.add_argument('--output', type=str, default='results/baseline',
                       help='ê²°ê³¼ ì €ì¥ ê²½ë¡œ')
    parser.add_argument('--samples', type=int, default=100,
                       help='í…ŒìŠ¤íŠ¸í•  ë¯¸ë¡œ ê°œìˆ˜')
    
    args = parser.parse_args()
    
    # Baseline ì‹¤í—˜ ì‹¤í–‰
    baseline = AStarBaseline(results_dir=args.output)
    baseline.run_baseline_experiment(args.subset, args.samples)


if __name__ == "__main__":
    main()