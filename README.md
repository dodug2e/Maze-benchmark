# ğŸŒ€ Mazeâ€‘Benchmark

> **Labâ€‘Seminar Edition (v2.0â€‘Lite)** â€“ *Ready for IsaacÂ Sim extension*

---

## 1Â ğŸ¯Â Purpose

Build an **extensible yet lightweight** benchmark framework for mazeâ€‘solving algorithms (ACOÂ variants, DQN, PPO, A\*, â€¦) that will pass the upcoming undergraduate lab seminar *and* scale later to IsaacÂ Sim.

---

## 2Â ğŸ“Â Directory Layout

```
maze-benchmark/
â”œâ”€â”€ algorithms/          # ACO, DQN, PPO â€¦ (one file per algo)
â”œâ”€â”€ configs/             # YAMLÂ â€“Â hyperâ€‘parameters
â”œâ”€â”€ datasets/            # âœ“  see SectionÂ 3
â”œâ”€â”€ scripts/             # train.py Â· profile.py Â· visualize.py
â”œâ”€â”€ utils/               # maze_io.py Â· profiler.py Â· seed.py
â”œâ”€â”€ tests/               # pytest test_*.py
â”œâ”€â”€ docs/                # MkDocs source
â”œâ”€â”€ maze_runner.py       # CLI entryâ€‘point
â”œâ”€â”€ pyproject.toml       # poetry build
â”œâ”€â”€ Dockerfile           # CUDAÂ +Â CPU compatible
â””â”€â”€ .github/workflows/ci.yml  # lintÂ +Â testsÂ +Â docker build
```

---

## 3Â ğŸ“¦Â Dataset Structure

The dataset is **preâ€‘split** intoÂ `trainÂ (10â€¯000)`,Â `validÂ (8â€¯000)`Â andÂ `testÂ (2â€¯000)` samples.

```
datasets/
â”œâ”€â”€ train/
â”‚Â Â  â”œâ”€â”€ img/            # 000001.png â€¦
â”‚Â Â  â”œâ”€â”€ metadata/       # 000001.json â€¦
â”‚Â Â  â”œâ”€â”€ arrays/         # 000001.npy  â€¦
â”‚Â Â  â””â”€â”€ dataset_info.json
â”œâ”€â”€ valid/
â”‚Â Â  â””â”€â”€ â€¦               # identical subâ€‘folders
â””â”€â”€ test/
    â””â”€â”€ â€¦
```

| subâ€‘folder          | content                                             | note                                 |
| ------------------- | --------------------------------------------------- | ------------------------------------ |
| `img/`              | 2â€‘D maze raster as **PNG**                          | 1Â fileÂ =Â 1Â sample                    |
| `metadata/`         | perâ€‘maze **JSON** (start/goal coords, name, etc.)   | *1:1 mapping toÂ img*                 |
| `arrays/`           | **NumPyÂ .npy** tensor (optional preâ€‘processed form) | shape & dtype in `dataset_info.json` |
| `dataset_info.json` | {Â `num_samples`, `version`, `sha256`Â }              | used by CI integrity test            |

\###Â 3.1Â LoadingÂ API

```python
from utils.maze_io import load_sample
img, meta, arr = load_sample("000001", subset="train")
```

`utils/maze_io.py` hides the folder logic and returns PILÂ Image, JSONâ€‘dict and optionally the NumPy array.

\###Â 3.2Â IntegrityÂ Check
Run once after cloning or in CI:

```bash
python scripts/inspect_dataset.py
```

*Verifies*: PNGÂ =Â JSONÂ =Â NPY count, checksum matches `dataset_info.json`.

---

## 4Â âš¡Â QuickÂ Start

```bash
# Install
poetry install

# Train (single epoch dryâ€‘run)
python scripts/train.py algo=PPO subset=train --dry-run

# Profile VRAM
python scripts/profile.py algo=ACO metric=vram subset=test
```

---

## 5Â âœ…Â DoneÂ Definition

| axis                | criterion                                     |
| ------------------- | --------------------------------------------- |
| **Functionality**   | CLI oneâ€‘liner trains & tests all 5 algorithms |
| **Performance**     | RTXÂ 3060Â (6â€¯GB)Â Â±10â€¯% FPSÂ &Â VRAM vsâ€¯baseline  |
| **Reproducibility** | `seed=42`, Dockerfile provided                |
| **Readability**     | `pylintÂ â‰¥â€¯8.5/10`, each moduleÂ â‰¤â€¯400Â LOC      |
| **Extensibility**   | New algorithmÂ = add 1Â file inÂ `algorithms/`   |

---

## 6Â ğŸ§ªÂ Labâ€‘SeminarÂ Checklist

1. `poetry install` â†’ deps OK
2. `pytest -q` â†’ all tests green
3. `python scripts/train.py algo=DQN --dry-run` â†’ 1â€¯epoch OK
4. `scripts/visualize.py` â†’ graphs saved toÂ `docs/`
5. Slides & README mention **IsaacÂ Sim capable**

---

## 7Â ğŸš€Â IsaacÂ SimÂ Extension (futureâ€‘proof)

*Replace* the Docker base image with NVIDIA Isaac and plug the simulator feed into `utils/maze_io.py` adapter hooks. No core changes required.

---

Happy benchmarking! ğŸ‰
